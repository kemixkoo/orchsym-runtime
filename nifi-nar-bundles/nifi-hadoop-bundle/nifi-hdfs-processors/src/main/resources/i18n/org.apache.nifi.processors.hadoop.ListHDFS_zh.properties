__CapabilityDescription=Retrieves a listing of files from HDFS. Each time a listing is performed, the files with the latest timestamp will be excluded and picked up during the next execution of the processor. This is done to ensure that we do not miss any files, or produce duplicates, in the cases where files with the same timestamp are written immediately before and after a single execution of the processor. For each file that is listed in HDFS, this processor creates a FlowFile that represents the HDFS file to be fetched in conjunction with FetchHDFS. This Processor is designed to run on Primary Node only in a cluster. If the primary node changes, the new Primary Node will pick up where the previous node left off without duplicating all of the data. Unlike GetHDFS, this Processor does not delete any data from HDFS.
__Tags=hadoop, HDFS, get, list, ingest, source, filesystem
Hadoop_Configuration_Resources.displayName=Hadoop Configuration Resources
Hadoop_Configuration_Resources.description=A file or comma separated list of files which contains the Hadoop file system configuration. Without this, Hadoop will search the classpath for a 'core-site.xml' and 'hdfs-site.xml' file or will revert to a default configuration. To use swebhdfs, see 'Additional Details' section of PutHDFS's documentation.
kerberos-credentials-service.displayName=Kerberos Credentials Service
kerberos-credentials-service.description=Specifies the Kerberos Credentials Controller Service that should be used for authenticating with Kerberos
Kerberos_Principal.displayName=Kerberos Principal
Kerberos_Principal.description=Kerberos principal to authenticate as. Requires nifi.kerberos.krb5.file to be set in your nifi.properties
Kerberos_Keytab.displayName=Kerberos Keytab
Kerberos_Keytab.description=Kerberos keytab associated with the principal. Requires nifi.kerberos.krb5.file to be set in your nifi.properties
Kerberos_Relogin_Period.displayName=Kerberos Relogin Period
Kerberos_Relogin_Period.description=Period of time which should pass before attempting a kerberos relogin.\n\nThis property has been deprecated, and has no effect on processing. Relogins now occur automatically.
Additional_Classpath_Resources.displayName=Additional Classpath Resources
Additional_Classpath_Resources.description=A comma-separated list of paths to files and/or directories that will be added to the classpath. When specifying a directory, all files with in the directory will be added to the classpath, but further sub-directories will not be included.
Distributed_Cache_Service.displayName=Distributed Cache Service
Distributed_Cache_Service.description=Specifies the Controller Service that should be used to maintain state about what has been pulled from HDFS so that if a new node begins pulling data, it won't duplicate all of the work that has been done.
Directory.displayName=Directory
Directory.description=The HDFS directory from which files should be read
Recurse_Subdirectories.displayName=Recurse Subdirectories
Recurse_Subdirectories.description=Indicates whether to list files from subdirectories of the HDFS directory
__AllowableValue.Recurse_Subdirectories.false.displayName=false
__AllowableValue.Recurse_Subdirectories.true.displayName=true
File_Filter.displayName=File Filter
File_Filter.description=Only files whose names match the given regular expression will be picked up
minimum-file-age.displayName=Minimum File Age
minimum-file-age.description=The minimum age that a file must be in order to be pulled; any file younger than this amount of time (based on last modification date) will be ignored
maximum-file-age.displayName=Maximum File Age
maximum-file-age.description=The maximum age that a file must be in order to be pulled; any file older than this amount of time (based on last modification date) will be ignored. Minimum value is 100ms.
__Relationship.success.description=All FlowFiles are transferred to this relationship
__WritesAttribute.filename.description=The name of the file that was read from HDFS.
__WritesAttribute.path.description=The path is set to the absolute path of the file's directory on HDFS. For example, if the Directory property is set to /tmp, then files picked up from /tmp will have the path attribute set to "./". If the Recurse Subdirectories property is set to true and a file is picked up from /tmp/abc/1/2/3, then the path attribute will be set to "/tmp/abc/1/2/3".
__WritesAttribute.hdfs.owner.description=The user that owns the file in HDFS
__WritesAttribute.hdfs.group.description=The group that owns the file in HDFS
__WritesAttribute.hdfs.lastModified.description=The timestamp of when the file in HDFS was last modified, as milliseconds since midnight Jan 1, 1970 UTC
__WritesAttribute.hdfs.length.description=The number of bytes in the file in HDFS
__WritesAttribute.hdfs.replication.description=The number of HDFS replicas for hte file
__WritesAttribute.hdfs.permissions.description=The permissions for the file in HDFS. This is formatted as 3 characters for the owner, 3 for the group, and 3 for other users. For example rw-rw-r--
__Stateful.description=After performing a listing of HDFS files, the latest timestamp of all the files listed and the latest timestamp of all the files transferred are both stored. This allows the Processor to list only files that have been added or modified after this date the next time that the Processor is run, without having to store all of the actual filenames/paths which could lead to performance problems. State is stored across the cluster so that this Processor can be run on Primary Node only and if a new Primary Node is selected, the new node can pick up where the previous node left off, without duplicating the data.
