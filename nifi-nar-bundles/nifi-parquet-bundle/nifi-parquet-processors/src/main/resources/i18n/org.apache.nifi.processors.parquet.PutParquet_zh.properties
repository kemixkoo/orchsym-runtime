__CapabilityDescription=Reads records from an incoming FlowFile using the provided Record Reader, and writes those records to a Parquet file. The schema for the Parquet file must be provided in the processor properties. This processor will first write a temporary dot file and upon successfully writing every record to the dot file, it will rename the dot file to it's final name. If the dot file cannot be renamed, the rename operation will be attempted up to 10 times, and if still not successful, the dot file will be deleted and the flow file will be routed to failure.  If any error occurs while reading records from the input, or writing records to the output, the entire dot file will be removed and the flow file will be routed to failure or retry, depending on the error.
__Tags=put, parquet, hadoop, HDFS, filesystem, record
Hadoop_Configuration_Resources.displayName=Hadoop Configuration Resources
Hadoop_Configuration_Resources.description=A file or comma separated list of files which contains the Hadoop file system configuration. Without this, Hadoop will search the classpath for a 'core-site.xml' and 'hdfs-site.xml' file or will revert to a default configuration. To use swebhdfs, see 'Additional Details' section of PutHDFS's documentation.
kerberos-credentials-service.displayName=Kerberos Credentials Service
kerberos-credentials-service.description=Specifies the Kerberos Credentials Controller Service that should be used for authenticating with Kerberos
Kerberos_Principal.displayName=Kerberos Principal
Kerberos_Principal.description=Kerberos principal to authenticate as. Requires nifi.kerberos.krb5.file to be set in your nifi.properties
Kerberos_Keytab.displayName=Kerberos Keytab
Kerberos_Keytab.description=Kerberos keytab associated with the principal. Requires nifi.kerberos.krb5.file to be set in your nifi.properties
Kerberos_Relogin_Period.displayName=Kerberos Relogin Period
Kerberos_Relogin_Period.description=Period of time which should pass before attempting a kerberos relogin.\n\nThis property has been deprecated, and has no effect on processing. Relogins now occur automatically.
Additional_Classpath_Resources.displayName=Additional Classpath Resources
Additional_Classpath_Resources.description=A comma-separated list of paths to files and/or directories that will be added to the classpath. When specifying a directory, all files with in the directory will be added to the classpath, but further sub-directories will not be included.
record-reader.displayName=Record Reader
record-reader.description=The service for reading records from incoming flow files.
Directory.displayName=Directory
Directory.description=The parent directory to which files should be written. Will be created if it doesn't exist.
compression-type.displayName=Compression Type
compression-type.description=The type of compression for the file being written.
__AllowableValue.compression-type.BROTLI.displayName=BROTLI
__AllowableValue.compression-type.GZIP.displayName=GZIP
__AllowableValue.compression-type.LZ4.displayName=LZ4
__AllowableValue.compression-type.LZO.displayName=LZO
__AllowableValue.compression-type.SNAPPY.displayName=SNAPPY
__AllowableValue.compression-type.UNCOMPRESSED.displayName=UNCOMPRESSED
__AllowableValue.compression-type.ZSTD.displayName=ZSTD
overwrite.displayName=Overwrite Files
overwrite.description=Whether or not to overwrite existing files in the same directory with the same name. When set to false, flow files will be routed to failure when a file exists in the same directory with the same name.
__AllowableValue.overwrite.false.displayName=false
__AllowableValue.overwrite.true.displayName=true
permissions-umask.displayName=Permissions umask
permissions-umask.description=A umask represented as an octal number which determines the permissions of files written to HDFS. This overrides the Hadoop Configuration dfs.umaskmode
remote-group.displayName=Remote Group
remote-group.description=Changes the group of the HDFS file to this value after it is written. This only works if NiFi is running as a user that has HDFS super user privilege to change group
remote-owner.displayName=Remote Owner
remote-owner.description=Changes the owner of the HDFS file to this value after it is written. This only works if NiFi is running as a user that has HDFS super user privilege to change owner
row-group-size.displayName=Row Group Size
row-group-size.description=The row group size used by the Parquet writer. The value is specified in the format of <Data Size> <Data Unit> where Data Unit is one of B, KB, MB, GB, TB.
page-size.displayName=Page Size
page-size.description=The page size used by the Parquet writer. The value is specified in the format of <Data Size> <Data Unit> where Data Unit is one of B, KB, MB, GB, TB.
dictionary-page-size.displayName=Dictionary Page Size
dictionary-page-size.description=The dictionary page size used by the Parquet writer. The value is specified in the format of <Data Size> <Data Unit> where Data Unit is one of B, KB, MB, GB, TB.
max-padding-size.displayName=Max Padding Size
max-padding-size.description=The maximum amount of padding that will be used to align row groups with blocks in the underlying filesystem. If the underlying filesystem is not a block filesystem like HDFS, this has no effect. The value is specified in the format of <Data Size> <Data Unit> where Data Unit is one of B, KB, MB, GB, TB.
enable-dictionary-encoding.displayName=Enable Dictionary Encoding
enable-dictionary-encoding.description=Specifies whether dictionary encoding should be enabled for the Parquet writer
__AllowableValue.enable-dictionary-encoding.false.displayName=false
__AllowableValue.enable-dictionary-encoding.true.displayName=true
enable-validation.displayName=Enable Validation
enable-validation.description=Specifies whether validation should be enabled for the Parquet writer
__AllowableValue.enable-validation.false.displayName=false
__AllowableValue.enable-validation.true.displayName=true
writer-version.displayName=Writer Version
writer-version.description=Specifies the version used by Parquet writer
__AllowableValue.writer-version.PARQUET_1_0.displayName=PARQUET_1_0
__AllowableValue.writer-version.PARQUET_2_0.displayName=PARQUET_2_0
remove-crc-files.displayName=Remove CRC Files
remove-crc-files.description=Specifies whether the corresponding CRC file should be deleted upon successfully writing a Parquet file
__AllowableValue.remove-crc-files.false.displayName=false
__AllowableValue.remove-crc-files.true.displayName=true
__Relationship.retry.description=Flow Files that could not be processed due to issues that can be retried are transferred to this relationship
__Relationship.success.description=Flow Files that have been successfully processed are transferred to this relationship
__Relationship.failure.description=Flow Files that could not be processed due to issue that cannot be retried are transferred to this relationship
__ReadsAttribute.filename.description=The name of the file to write comes from the value of this attribute.
__WritesAttribute.filename.description=The name of the file is stored in this attribute.
__WritesAttribute.absolute.hdfs.path.description=The absolute path to the file is stored in this attribute.
__WritesAttribute.record.count.description=The number of records written to the Parquet file
__Restriction.write-filesystem.label=write filesystem
__Restriction.write-filesystem.explanation=Provides operator the ability to write any file that NiFi has access to in HDFS or the local filesystem.
